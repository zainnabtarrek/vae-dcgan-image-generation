# vae-dcgan-image-generation

This project implements and compares Variational Autoencoders (VAE) and Deep Convolutional GANs (DCGAN) for generating grayscale and RGB images.

## Features
### Part 1: VAE on Grayscale Images
- Built a Variational Autoencoder model for grayscale images.
- Developed a GUI for user interaction.
![image](https://github.com/user-attachments/assets/9f52ce24-8503-43a8-b9d8-893928191533)
 

### Part 2: VAE on RGB Images
- Extended the VAE model to RGB images.
- Developed a GUI for RGB image generation.

### Part 3: Custom Dataset
- Applied the VAE to a custom-created RGB dataset.

### Part 4: DCGAN Implementation
- Generated images using a simple implementation of Deep Convolutional GANs.

### Part 5: Comparison
- Compared the quality of images generated by VAE and DCGAN.

## Dataset
- Grayscale: MNIST Dataset (downloaded automatically by PyTorch).
- RGB: CIFAR-10 (for Parts 2 and 3) and custom-created RGB dataset (Part 3).

## Methodology:

### Loss Functions:
-Variational Autoencoder (VAE):
The loss function for the VAE consists of two components:

1- Reconstruction Loss: Measures how well the decoder reconstructs the input using Mean Squared Error (MSE).
2- KL Divergence Loss: Encourages the latent space distribution to approximate a standard normal distribution.

-Deep Convolutional Generative Adversarial Network (DCGAN):
Binary Cross-Entropy Loss (BCELoss) is used to measure the difference between the generated images and the real images during training.

## GUI Features
- Interactive input for generating images with VAE.
- Supports grayscale and RGB image generation.

## Future Work
- Extend the project to include more advanced generative models.
- Apply image generation models to other datasets and domains.
- Improve the archtecture and performance of DCGAN and VAE on RGB images.
